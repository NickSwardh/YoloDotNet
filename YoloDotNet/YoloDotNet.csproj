<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net8.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <AllowUnsafeBlocks>True</AllowUnsafeBlocks>
    <Title>YoloDotNet</Title>
    <PackageProjectUrl>https://github.com/NickSwardh/YoloDotNet</PackageProjectUrl>
    <RepositoryUrl>https://github.com/NickSwardh/YoloDotNet</RepositoryUrl>
    <PackageTags>yolo;yolov5u;yolov8;yolov9;yolov10;yolov11;yolov12;yolo-world;yolo-e;onnx;cuda;gpu;tensor;tensorrt;classification;object-detection;segmentation;pose-estimation;obb;oriented-bounding-box;image-processing;computer-vision;video-processing;media-processing;ffmpeg;skiasharp;imagesharp;tracking;machine-learning;real-time;inference</PackageTags>
    <PackAsTool>False</PackAsTool>
    <PackageIcon>icon.png</PackageIcon>
    <PackageReadmeFile>README.md</PackageReadmeFile>
    <Description>YoloDotNet is a blazing-fast, modern C# library for real-time object detection, classification, segmentation, OBB, pose estimation — and tracking. Powered by ONNX Runtime, CUDA acceleration, and now NVIDIA TensorRT, it effortlessly handles images and video streams with ultra-low latency. Supports a wide range of cutting-edge models including YOLOv5u, YOLOv8, YOLOv9, YOLOv10, YOLOv11, YOLOv12, Yolo-World, and YOLO-E. Whether you’re building smart cameras, analytics dashboards, or unlocking real-time machine vision, YoloDotNet has you covered.</Description>
    <Authors>Nick Swardh</Authors>
	<Version>3.1</Version>
    <Company />
    <PackageRequireLicenseAcceptance>True</PackageRequireLicenseAcceptance>
    <PackageLicenseExpression>GPL-3.0-or-later</PackageLicenseExpression>
    <PackageReleaseNotes>Say hello to YoloDotNet 3.1, packed with blazing fast inference thanks to brand-new TensorRT support! Now you can harness NVIDIA’s TensorRT execution provider to supercharge your YOLO models with ultra-low latency and killer throughput — perfect for real-time and edge deployments.

TensorRT Integration:
Enjoy powerful CUDA-accelerated inference that pushes your models to new heights with minimal fuss.

Segmentation Improvements:
Segmentation inference just got leaner and meaner — CPU inference is up to 11% faster, GPU up to 28% quicker, with memory usage slashed by a massive 85%. Your vision pipelines are now faster, lighter, and more reliable.</PackageReleaseNotes>
    <Copyright>Copyright © 2023 Nick Swardh</Copyright>
  </PropertyGroup>

  <ItemGroup>
    <None Include="..\README.md">
      <Pack>True</Pack>
      <PackagePath>\</PackagePath>
    </None>
    <None Include="D:\Documents\Yolodotnet Icon\icon.png">
      <Pack>True</Pack>
      <PackagePath>\</PackagePath>
    </None>
  </ItemGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.ML.OnnxRuntime.Gpu" Version="1.22.1" />
    <PackageReference Include="SkiaSharp" Version="3.119.0" />
  </ItemGroup>

</Project>
