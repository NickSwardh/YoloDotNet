<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net8.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <AllowUnsafeBlocks>true</AllowUnsafeBlocks>
    <Title>YoloDotNet CUDA Execution Provider</Title>
    <Version>1.0</Version>
    <Authors>Niklas Swärd</Authors>
    <Copyright>Niklas Swärd</Copyright>
    <PackageIcon>icon.png</PackageIcon>
    <PackageReadmeFile>README.md</PackageReadmeFile>
    <Description>CUDA and TensorRT execution provider for YoloDotNet, enabling GPU-accelerated inference on NVIDIA hardware using ONNX Runtime.

This execution provider supports CUDA for general GPU acceleration and optional NVIDIA TensorRT integration for maximum performance, lower latency, and optimized engine execution. It is designed for high-throughput and real-time inference workloads on Windows and Linux systems with supported NVIDIA GPUs.

The provider is fully compatible with the YoloDotNet core library and follows the new modular, execution-provider-agnostic architecture introduced in YoloDotNet v4.0.</Description>
    <PackageTags>yolo;yolodotnet;onnx;onnxruntime;cuda;tensorrt;nvidia;gpu;gpu-acceleration;inference;machine-learning;deep-learning;computer-vision;object-detection;segmentation;pose-estimation;real-time;high-performance;windows;linux</PackageTags>
    <PackageReleaseNotes>This is the first standalone release of the CUDA execution provider for YoloDotNet following the introduction of the new modular architecture.

The CUDA execution provider enables GPU-accelerated inference using ONNX Runtime’s CUDA backend and supports optional NVIDIA TensorRT integration for maximum performance, lower latency, and optimized execution on supported NVIDIA GPUs.

This provider targets high-performance and real-time inference workloads on Windows and Linux systems and requires the CUDA Toolkit and cuDNN to be installed on the host system. It is fully compatible with the YoloDotNet core library and follows the new execution-provider-agnostic design.</PackageReleaseNotes>
  </PropertyGroup>

  <ItemGroup>
    <None Include="..\icon.png">
      <Pack>True</Pack>
      <PackagePath>\</PackagePath>
    </None>
  </ItemGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.ML.OnnxRuntime.Gpu" Version="1.23.2" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\YoloDotNet\YoloDotNet.csproj" />
  </ItemGroup>

  <ItemGroup>
    <None Update="README.md">
      <Pack>True</Pack>
      <PackagePath>\</PackagePath>
    </None>
  </ItemGroup>

</Project>
